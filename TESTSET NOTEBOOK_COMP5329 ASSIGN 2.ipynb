{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP5329 ASSIGNMENT \n",
    "## TESTSET NOTEBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# --------------\n",
    "# BASIC PACKAGES\n",
    "# --------------\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "seed = 99\n",
    "np.random.seed(99)\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import imageio\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "# ---------------------------\n",
    "# TENSORFLOW & KERAS PACKAGES\n",
    "# ---------------------------\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ------------------------------------\n",
    "# SCIKIT-LEARN PACKAGES FOR EVALUATION\n",
    "# ------------------------------------\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Image Import Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def READ_IN_IMGS(X_train_folder, X_labels, img_height, img_width):\n",
    "    \n",
    "    start = time.time()\n",
    "    no_of_samples = X_labels.shape[0]\n",
    "    X_train_array = np.zeros((no_of_samples,img_height,img_width))\n",
    "    j=0\n",
    "    for i in X_labels:\n",
    "        img_ary = imageio.imread(X_train_folder+i)\n",
    "        img_ary = img_ary.reshape((1,) + img_ary.shape) \n",
    "        X_train_array[j] = img_ary\n",
    "        if j < X_train_array.shape[0]:\n",
    "            j+=1\n",
    "    X_train_array = X_train_array.astype('float32')\n",
    "    X_train_array = X_train_array / 255\n",
    "    print(time.time() - start)\n",
    "    \n",
    "    return(X_train_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listdir for filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = 'test_set/'\n",
    "\n",
    "test_labels = np.asarray(os.listdir(test_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18848,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'img016475.png'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!CHANGE TO '/test-set' & img_files_ary!!\n",
    "### Import Test-set & Reshape for Model Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.829750061035156\n"
     ]
    }
   ],
   "source": [
    "# X_test = READ_IN_IMGS('test-set/',img_files_ary,128,128)\n",
    "\n",
    "X_test = READ_IN_IMGS('test_set/',test_labels,128,128)\n",
    "X_test = X_test.reshape(X_test.shape[0], 128, 128, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18848, 128, 128, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMERGENCY ONLY\n",
    "#### If model and weights fail to load - Run Below Cell to Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (D) CNN3232_3232_3232_FC512F512_drpt_BN(momentum=0.6)\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, (3, 3), padding='same', input_shape=X_test.shape[1:]))\n",
    "# model.add(BatchNormalization(momentum=0.6))\n",
    "# model.add(Activation('relu'))\n",
    "# print(model.output_shape)\n",
    "# model.add(Conv2D(32, (3, 3)))\n",
    "# model.add(BatchNormalization(momentum=0.6))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "# print(model.output_shape)\n",
    "\n",
    "# model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "# model.add(BatchNormalization(momentum=0.6))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(32, (3, 3)))\n",
    "# model.add(BatchNormalization(momentum=0.6))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "# model.add(BatchNormalization(momentum=0.6))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(32, (3, 3)))\n",
    "# model.add(BatchNormalization(momentum=0.6))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# print(model.output_shape)\n",
    "# model.add(Flatten())\n",
    "# print(model.output_shape)\n",
    "\n",
    "# model.add(Dense(512)) \n",
    "# model.add(BatchNormalization(momentum=0.6))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(512)) \n",
    "# model.add(BatchNormalization(momentum=0.6))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Dense(62))\n",
    "# model.add(BatchNormalization(momentum=0.6))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "# loaded_model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# checkpoint = ModelCheckpoint(\"model_weights_BEST.hdf5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# loaded_model = model.fit(X_train, y_train,\n",
    "#                   batch_size=32,\n",
    "#                   epochs=26, \n",
    "#                     callbacks=[csv_logger], \n",
    "#                     validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model & Weights \n",
    "# !!CHECK MODEL AND WEIGHT FILES!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(\"Model_D_model.json\", 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.load_weights(\"ModelD_weights.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18848/18848 [==============================] - 559s 30ms/step\n"
     ]
    }
   ],
   "source": [
    "predict_output = loaded_model.predict(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0115311 , 0.00838307, 0.09105012, 0.00180046, 0.00027707,\n",
       "       0.00113677, 0.00164001, 0.00336625, 0.00160761, 0.00051545,\n",
       "       0.00471408, 0.00090216, 0.08417323, 0.00101702, 0.00243654,\n",
       "       0.00230663, 0.00149046, 0.00161913, 0.03645968, 0.00689677,\n",
       "       0.00052037, 0.00782981, 0.00282324, 0.00160071, 0.00864081,\n",
       "       0.02087268, 0.02309011, 0.03830638, 0.00533321, 0.00312428,\n",
       "       0.00852113, 0.01550352, 0.0038254 , 0.01014446, 0.00650829,\n",
       "       0.03987342, 0.06664874, 0.00084196, 0.05275222, 0.09442962,\n",
       "       0.1375522 , 0.00032259, 0.00355794, 0.00041866, 0.01861526,\n",
       "       0.00399223, 0.00452197, 0.08315362, 0.00045881, 0.00119734,\n",
       "       0.01032652, 0.00129686, 0.00034967, 0.00131174, 0.00220845,\n",
       "       0.00121821, 0.0087442 , 0.00997446, 0.00438413, 0.00814923,\n",
       "       0.00318857, 0.02054344], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'img016475.png'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert soft-max to class outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_outputs = np.argmax(predict_output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'img012178.png'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[-32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_outputs[-33]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack img filenames array & class outputs horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_predictclass_array = np.stack((test_labels,class_outputs), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18848, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_predictclass_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    " filename_predictclass_array_SORTED = filename_predictclass_array[filename_predictclass_array[:,0].argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18848, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_predictclass_array_SORTED.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to 'test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('test.txt', filename_predictclass_array_SORTED, fmt='%s', delimiter=' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "5329_env",
   "language": "python",
   "name": "5329_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
